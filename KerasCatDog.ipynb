{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca56471-da76-4142-a65e-68acc4a0162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "for filename in filenames:\n",
    "print(os.path.join(dirname, filename))\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ee962-8d94-4f66-a0bf-674c27af550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def unzip_files(directory_path, extract_to_path):\n",
    "for filename in os.listdir(directory_path):\n",
    "if filename.endswith('.zip'):\n",
    "zip_file_path = os.path.join(directory_path, filename)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "zip_ref.extractall(extract_to_path)\n",
    "main_directory = '/kaggle/input/dogs-vs-cats-redux-kernels-edition'\n",
    "extract_to_path = '/kaggle/working/'\n",
    "unzip_files(main_directory, extract_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01258584-ddf3-4d62-8204-343690fc1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense,Flatten,Dropout,BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.activations import sigmoid\n",
    "from keras.applications import ResNetRS420\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense,Flatten,Dropout,BatchNormalization\n",
    "from keras.applications import DenseNet121,DenseNet169,DenseNet201,RegNetY320,RegNetX320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccaf5d4-153b-47b3-b08a-ba0f4e4b31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir= '/kaggle/working/train'\n",
    "train_data=glob.glob(train_dir+'**/*.jpg',root_dir=train_dir)\n",
    "train_data=train_data[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661df273-f09b-46f0-86ee-ca90fbc211d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "for img_path in train_data:\n",
    "img= cv2.imread(img_path)\n",
    "img= cv2.resize(img,(256,256))\n",
    "img= img/255\n",
    "X_train.append(img)\n",
    "X_train= np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf61d50-86d2-4425-a067-d978a4fa86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1f5dc-5de3-4b23-ab7c-7865cfe377a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_name= glob.glob('*.jpg',root_dir= train_dir)\n",
    "files_name[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f94634-85a6-4ad4-b34f-a134c205ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [file_name.split('.')[0] for file_name in files_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b123145-9a38-449f-85ac-940004f1f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1359327-6662-40df-a265-279bd6a0346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd12a3e9-f629-4c9d-b1fe-73116b52d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder= LabelEncoder()\n",
    "y_train= encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dacbce1-66a7-4402-87d0-e38fd5e52a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(min(16, len(X_train))):\n",
    "plt.subplot(4, 4, i+1)\n",
    "plt.imshow(X_train[i])\n",
    "plt.title(y_train[i])\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e5910-9e4b-496b-9511-2e1505b4336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "layer.trainable = False\n",
    "model = tf.keras.models.Sequential([\n",
    "base_model,\n",
    "BatchNormalization(),\n",
    "Flatten(),\n",
    "Dense(256,activation='relu'),\n",
    "BatchNormalization(),\n",
    "Dense(128,activation='relu'),\n",
    "Dense(64,activation='relu'),\n",
    "Dropout(0.5),\n",
    "Dense(1,activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e53c0d-6de8-49d7-8cb8-12c41df3c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fcf99-5c10-4fd9-9da7-2de5bd04220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate schedule\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.00001,\n",
    "    decay_steps=2000,\n",
    "    decay_rate=0.7\n",
    ")\n",
    "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465171c-b33f-4ead-9f52-77b1c5e43d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, verbose=1, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac32c17-0cf0-44ea-8677-e8f8ede9f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "# Plot training accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "# Plot training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7586fd-d95a-4eea-9cca-eab394c59231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('catvsdog.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de346c-f55e-47a2-9044-7882fe15686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model= load_model('/kaggle/working/catvsdog.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ef054-cb13-47a4-9fe1-9ab358869181",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir= '/kaggle/working/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e9a79-1852-409b-a1bf-f1438cc99bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=glob.glob(test_dir+'/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b884ef-cb7b-4504-a202-8621a4b25f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test=[]\n",
    "# for img_path in test_data:\n",
    "# img= cv2.imread(img_path)\n",
    "# img= cv2.resize(img,(256,256))\n",
    "# img= img/255\n",
    "# X_test.append(img)\n",
    "# X_test= np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab7bf84-4b04-46ae-a5d7-bc03f6aed06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "# Define a function to preprocess images\n",
    "def preprocess_image(img):\n",
    "img = cv2.resize(img, (256, 256))\n",
    "img = img / 255.0 # Normalize pixel values\n",
    "img = np.expand_dims(img, axis=0)\n",
    "return img\n",
    "# Example of batch processing\n",
    "batch_size = 32\n",
    "# Initialize an empty list to store predictions\n",
    "all_predictions = []\n",
    "for i in range(0, len(test_data), batch_size):\n",
    "batch_paths = test_data[i:i + batch_size]\n",
    "batch_images = [cv2.imread(img_path) for img_path in batch_paths]\n",
    "batch_images = [preprocess_image(img) for img in batch_images]\n",
    "# Convert the batch to a numpy array\n",
    "batch_data = np.vstack(batch_images)\n",
    "# Predictions for the current batch\n",
    "predictions = model.predict(batch_data)\n",
    "# Extend the predictions list\n",
    "all_predictions.extend(predictions.flatten())\n",
    "# Now, 'all_predictions' contains predictions for all test images\n",
    "all_predictions = np.array(all_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
